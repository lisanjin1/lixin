import glob
import itertools
import os
import pickle
import re
from functools import reduce
from typing import List, Tuple, Dict, Any

import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import KFold, cross_val_predict
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_predict
from sklearn.inspection import PartialDependenceDisplay
import shap
from sklearn.inspection import permutation_importance

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from log import log


# 1ï¸âƒ£ å¤„ç†åˆ—å
def clean_col(col):
    """
    æ¸…æ´—åˆ—åï¼š
    1ï¸âƒ£ æå–åˆ—åä¸­çš„æ•°å­—éƒ¨åˆ†ï¼ˆä¾‹å¦‚ '05ul' â†’ '5', '0.1ul' â†’ '0.1'ï¼‰
    2ï¸âƒ£ è‹¥æ— æ•°å­—éƒ¨åˆ†ï¼Œåˆ™ä¿ç•™åŸåˆ—å
    3ï¸âƒ£ è‹¥ä»¥0å¼€å¤´ï¼Œåˆ™å°†åˆ—åæ”¹ä¸º '0'
    4ï¸âƒ£ è‹¥æ˜¯çº¯æ•°å­—ï¼Œåˆ™å»é™¤å‰å¯¼0
    """
    col = str(col)

    # å¦‚æœæ˜¯ä»¥0å¼€å¤´ï¼Œåˆ™ç›´æ¥æ”¹ä¸º '0'
    if col.startswith('0') and not col.startswith('0.'):
        return '0'

    # æå–æ•°å­—ï¼ˆæ”¯æŒå°æ•°ï¼‰
    nums = re.findall(r'\d+\.?\d*', col)
    # print(nums)

    if len(nums) == 1:
        num = nums[0]  # æå–ç¬¬ä¸€ä¸ªæ•°å­—
        try:
            return str(float(num)) if '.' in num else str(int(num))
        except ValueError:
            return num
    else:
        # å¦‚æœæ²¡æœ‰æ•°å­—éƒ¨åˆ†ï¼Œåˆ™ä¿ç•™åŸæ ·
        return col


# 2ï¸âƒ£ æŒ‰ç…§â€œå®é™…æ•°å€¼å¤§å°â€æ’åºåˆ—ï¼ˆä»…å¯¹èƒ½è½¬ä¸ºæ•°å­—çš„åˆ—æ’åºï¼‰
def sort_key(c):
    try:
        return int(c)
    except ValueError:
        # å¦‚æœä¸èƒ½è½¬æˆæ•°å­—ï¼Œå°±æ’åœ¨æœ€å
        return float('-1')


def extract_data_from_file(filepath):
    # ranges = [(-np.inf, np.inf)]

    """ä»ä¸€ä¸ªxlsxæ–‡ä»¶æå–ç‰¹å¾å‘é‡ï¼ˆåŒºé—´å†…æ‰€æœ‰æ›²çº¿çŸ©é˜µçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼‰"""
    log.info(f"loading file: {filepath}")
    df = pd.read_excel(filepath)
    # åˆ é™¤åˆ—åä¸­å«ä¸‹åˆ’çº¿çš„åˆ—
    df = df[[c for c in df.columns if '_' not in str(c)]]
    # å¤„ç†dfçš„åˆ—
    df.columns = [clean_col(c) for c in df.columns]
    # log.info(df.columns)
    # æŒ‰ç…§å®é™…æ•°å€¼å¤§å°æ’åº
    df = df[sorted(df.columns, key=sort_key)]
    # log.debug(df.columns)

    # æ¨ªåæ ‡ (Voltage)
    # voltage = df.iloc[:, 0].values.ravel()   # ä¿è¯ä¸€ç»´
    # currents = df.iloc[:, 1:].values        # å…¶ä»–åˆ—ä¸ºç”µæµçŸ©é˜µ (nç‚¹ Ã— mæ›²çº¿)

    return df


def load_dataset(base_dir):
    """è¯»å–æ‰€æœ‰æ–‡ä»¶"""
    dfs = []
    for filepath in glob.glob(os.path.join(base_dir, "*.xlsx")):
        df = extract_data_from_file(filepath)
        dfs.append(df)

    # 1ï¸âƒ£ è·å–å…¬å…±åˆ—åäº¤é›†
    common_cols = list(reduce(lambda x, y: x & y, [set(df.columns) for df in dfs]))
    log.debug(f"å…¬å…±åˆ— ({len(common_cols)} ä¸ª)ï¼š{common_cols}")

    if len(common_cols) < 10:
        # å…¬å…±åˆ—å°äº10åˆ—ï¼Œå¯»æ‰¾åˆ—æ•°æœ€å¤šçš„ç»„åˆ
        result = find_best_common_columns_combination(dfs, n_min=3)

        print("æœ€ä½³ç»„åˆç´¢å¼•ï¼š", result["best_combo_indices"])
        print("ç»„åˆå¤§å°ï¼š", result["best_combo_size"])
        print("å…¬å…±åˆ—æ•°ï¼š", result["common_col_count"])
        print("å…¬å…±åˆ—åï¼š", result["common_cols"])
        # å–å‡ºè¿™äº› df
        best_dfs = [dfs[i] for i in result["best_combo_indices"]]
        # é‡æ–°è¦†ç›–å…¬å…±åˆ—
        common_cols = list(reduce(lambda x, y: x & y, [set(df.columns) for df in best_dfs]))
        log.warning(f"æ–°çš„å…¬å…±åˆ— ({len(common_cols)} ä¸ª)ï¼š{common_cols}")
        # é‡æ–°è¦†ç›–dfs
        dfs = best_dfs

    # 2ï¸âƒ£ æ‰€æœ‰dfä»…ä¿ç•™å…¬å…±åˆ—
    dfs = [df[common_cols] for df in dfs]

    # æŒ‰ç…§è¡¨å¤´å…·ä½“æ•°å€¼å¤§å°æ’åº
    dfs = [df[sorted(df.columns, key=sort_key)] for df in dfs]

    # log.info(dfs, len(dfs))

    return dfs


def find_best_common_columns_combination(dfs, n_min=3):
    """
    ä»å¤šä¸ª DataFrame ä¸­ï¼Œæ‰¾å‡ºæ‰€æœ‰å¤§å° >= n_min çš„ç»„åˆï¼Œ
    å¹¶è¿”å›å…¬å…±åˆ—æ•°æœ€å¤šçš„ç»„åˆåŠå…¶å…¬å…±åˆ—åã€‚

    å‚æ•°ï¼š
        dfs: List[pd.DataFrame]
        n_min: int, æœ€å°ç»„åˆå¤§å°ï¼ˆä¾‹å¦‚3è¡¨ç¤ºåªè€ƒè™‘3ä¸ªåŠä»¥ä¸Šçš„ç»„åˆï¼‰

    è¿”å›ï¼š
        result: dict åŒ…å«æœ€ä½³ç»„åˆçš„ä¿¡æ¯
    """
    m = len(dfs)
    best_combo = None
    best_common_cols = set()
    best_n = 0

    # å°†æ¯ä¸ª df çš„åˆ—é›†åˆä¿å­˜
    col_sets = [set(df.columns) for df in dfs]

    for n in range(n_min, m + 1):
        for combo in itertools.combinations(range(m), n):
            common_cols = set.intersection(*(col_sets[i] for i in combo))
            if len(common_cols) > len(best_common_cols):
                best_common_cols = common_cols
                best_combo = combo
                best_n = n

    result = {
        "best_combo_indices": best_combo,
        "best_combo_size": best_n,
        "common_col_count": len(best_common_cols),
        "common_cols": sorted(list(best_common_cols)),
    }
    return result


def build_feature_target_from_dfs(
        dfs: List[pd.DataFrame],
        train_ratio: float = 0.9,
        include_voltage: bool = True,
        include_baseline: bool = True
) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
    """
    å°† dfsï¼ˆlist of DataFrameï¼‰è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ çš„ X, yã€‚
    å‡è®¾ï¼šæ¯ä¸ª df çš„åˆ—é¡ºåºä¸º [voltage, baseline, cur_1, cur_2, ..., cur_n]
    train_ratio è¡¨ç¤ºç”¨å‰ train_ratio çš„â€œç”µæµåˆ—â€ä½œä¸ºè¾“å…¥ï¼Œå…¶ä½™ä½œä¸ºè¾“å‡ºã€‚

    è¿”å›ï¼š
      X: shape (n_samples, n_features)
      y: shape (n_samples, n_targets)
      meta: dict åŒ…å« train_cols, test_cols, train_n, test_n, include_* ç­‰ä¿¡æ¯
    """
    assert len(dfs) > 0, "dfs åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
    # ä»¥ç¬¬ä¸€ä¸ª df ä¸ºæ ‡å‡†ï¼Œæ£€æŸ¥åˆ—æ•°ä¸€è‡´æ€§ï¼ˆå¯æ ¹æ®éœ€è¦åšæ›´ä¸¥æ ¼çš„æ ¡éªŒï¼‰
    n_cols = dfs[0].shape[1]
    assert n_cols >= 3, "æ¯ä¸ª df è‡³å°‘éœ€è¦ 3 åˆ—ï¼ˆvoltage, baseline, >=1 current åˆ—ï¼‰"

    # å½“å‰ç”µæµåˆ—æ•°é‡ï¼ˆå‡å®šæ¯ä¸ª df åˆ—æ•°ç›¸åŒï¼‰
    n_current = n_cols - 2
    train_n = int(np.floor(n_current * train_ratio))
    train_n = max(1, train_n)  # è‡³å°‘ 1 åˆ—ç”¨äºè®­ç»ƒ
    test_n = n_current - train_n
    if test_n < 1:
        # å¼ºåˆ¶ä¿ç•™è‡³å°‘ 1 åˆ—ä½œæµ‹è¯•
        train_n = n_current - 1
        test_n = 1

    # åˆ—å
    train_cols = list(dfs[0].columns[2:2 + train_n])
    test_cols = list(dfs[0].columns[2 + train_n: 2 + train_n + test_n])

    X_list = []
    y_list = []

    for df in dfs:
        # ç®€å•æ ¡éªŒï¼šç¡®ä¿åˆ—æ•°ä¸€è‡´
        if df.shape[1] != n_cols:
            raise ValueError("æ‰€æœ‰ DataFrame å¿…é¡»å…·æœ‰ç›¸åŒåˆ—æ•°ï¼ˆç¬¬ä¸€ä¸ª df çš„åˆ—æ•°ä¸ºåŸºå‡†ï¼‰")

        vol = df.iloc[:, 0].to_numpy()  # shape (625,)
        baseline = df.iloc[:, 1].to_numpy()  # shape (625,)
        currents = df.iloc[:, 2:].to_numpy()  # shape (625, n_current)

        for i in range(currents.shape[0]):  # å¯¹æ¯ä¸€è¡Œï¼ˆç”µå‹ç‚¹ï¼‰äº§ç”Ÿä¸€ä¸ªæ ·æœ¬
            features = []
            if include_voltage:
                features.append(vol[i])
            if include_baseline:
                features.append(baseline[i])
            # å‰ train_n åˆ—ä½œä¸ºç‰¹å¾
            features.extend(currents[i, :train_n].tolist())
            X_list.append(features)
            # å test_n åˆ—ä½œä¸ºå¤šè¾“å‡ºç›®æ ‡
            y_list.append(currents[i, train_n:].tolist())

    X = np.array(X_list, dtype=float)
    y = np.array(y_list, dtype=float)

    meta = {
        'train_cols': train_cols,
        'test_cols': test_cols,
        'train_n': train_n,
        'test_n': test_n,
        'include_voltage': include_voltage,
        'include_baseline': include_baseline,
        'voltage_col': dfs[0].columns[0],
        'baseline_col': dfs[0].columns[1]
    }
    return X, y, meta


def train_and_evaluate_multioutput(
        X: np.ndarray,
        y: np.ndarray,
        cv_folds: int = 5,
        random_state: int = 42,
        n_estimators: int = 200,
) -> Tuple[Pipeline, Dict[str, Any], np.ndarray]:
    """
    ä½¿ç”¨ Pipeline(imputer->scaler->RandomForest) å¯¹ X,y è¿›è¡Œäº¤å‰éªŒè¯è¯„ä¼°å¹¶åœ¨å…¨éƒ¨æ•°æ®ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹ã€‚
    è¿”å›ï¼šfitted_pipeline, metrics_dict, y_pred_cvï¼ˆäº¤å‰éªŒè¯é¢„æµ‹ï¼Œç”¨äºè¯„ä¼°ï¼‰
    """
    # Pipeline: ç¼ºå¤±å€¼å¡«å…… -> æ ‡å‡†åŒ– -> éšæœºæ£®æ—å›å½’ï¼ˆå¤šè¾“å‡ºï¼‰
    pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler()),
        ('reg', RandomForestRegressor(n_estimators=n_estimators, n_jobs=-1, random_state=random_state))
    ])

    # äº¤å‰éªŒè¯é¢„æµ‹ï¼ˆç”¨äºè¯„ä¼°ï¼‰
    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)
    # cross_val_predict æ”¯æŒå¤šè¾“å‡ºå›å½’å™¨
    y_pred_cv = cross_val_predict(pipeline, X, y, cv=kf, method='predict', n_jobs=-1)

    # è®¡ç®—æ¯ä¸ªè¾“å‡ºï¼ˆæ¯ä¸ªè¢«é¢„æµ‹åˆ—ï¼‰çš„æŒ‡æ ‡
    metrics = {}
    rmse_list, mae_list, r2_list = [], [], []
    for j in range(y.shape[1]):
        rmse = mean_squared_error(y[:, j], y_pred_cv[:, j], squared=False)
        mae = mean_absolute_error(y[:, j], y_pred_cv[:, j])
        r2 = r2_score(y[:, j], y_pred_cv[:, j])
        metrics[f'output_{j}'] = {'rmse': float(rmse), 'mae': float(mae), 'r2': float(r2)}
        rmse_list.append(rmse)
        mae_list.append(mae)
        r2_list.append(r2)

    metrics['aggregate'] = {
        'rmse_mean': float(np.mean(rmse_list)),
        'mae_mean': float(np.mean(mae_list)),
        'r2_mean': float(np.mean(r2_list))
    }

    # åœ¨æ‰€æœ‰æ•°æ®ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹
    pipeline.fit(X, y)

    return pipeline, metrics, y_pred_cv


def predict_and_attach(
        model: Pipeline,
        dfs: List[pd.DataFrame],
        meta: Dict[str, Any],
        overwrite: bool = False,
        pred_suffix: str = '_pred'
) -> List[pd.DataFrame]:
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„ model å¯¹ dfs ä¸­æ¯ä¸ª df çš„å test_n åˆ—é€è¡Œé¢„æµ‹ï¼Œ
    å¹¶å°†é¢„æµ‹ç»“æœä»¥æ–°åˆ—ï¼ˆåˆ—å + pred_suffixï¼‰é™„åŠ åˆ° df çš„å‰¯æœ¬ä¸­ï¼ˆé»˜è®¤ä¸è¦†ç›–åŸåˆ—ï¼‰ã€‚
    è¿”å›ï¼špredicted_dfsï¼ˆlist of DataFrameï¼‰
    """
    train_n = meta['train_n']
    predicted_dfs = []

    for df in dfs:
        df_copy = df.copy()
        vol = df_copy.iloc[:, 0].to_numpy()
        baseline = df_copy.iloc[:, 1].to_numpy()
        currents = df_copy.iloc[:, 2:].to_numpy()  # shape (625, n_current)
        rows = currents.shape[0]

        X_rows = []
        for i in range(rows):
            features = []
            if meta['include_voltage']:
                features.append(vol[i])
            if meta['include_baseline']:
                features.append(baseline[i])
            features.extend(currents[i, :train_n].tolist())
            X_rows.append(features)
        X_rows = np.array(X_rows, dtype=float)

        y_hat = model.predict(X_rows)  # shape (rows, test_n)

        # æŠŠé¢„æµ‹å€¼å†™å› DataFrameï¼ˆä»¥æ–°åˆ—æˆ–è¦†ç›–åŸåˆ—ï¼‰
        for j, col in enumerate(meta['test_cols']):
            if overwrite:
                col_name = col
            else:
                col_name = f"{col}{pred_suffix}"
            df_copy[col_name] = y_hat[:, j]

        predicted_dfs.append(df_copy)

    return predicted_dfs


def evaluate_predictions_on_dfs(
        predicted_dfs: List[pd.DataFrame],
        original_dfs: List[pd.DataFrame],
        meta: Dict[str, Any],
        pred_suffix: str = '_pred'
) -> List[Dict[str, Any]]:
    """
    é€ä¸ª df è®¡ç®—é¢„æµ‹åˆ—ä¸çœŸå®åˆ—ä¹‹é—´çš„ RMSE/MAE/R2ï¼Œè¿”å›æ¯ä¸ª df çš„å­—å…¸ã€‚
    å‡å®š predict_and_attach ä½¿ç”¨é»˜è®¤è¡Œä¸ºï¼ˆæ–°å¢åˆ—å = åŸåˆ— + pred_suffixï¼‰ã€‚
    """
    results = []
    for df_pred, df_true in zip(predicted_dfs, original_dfs):
        per_col = {}
        rmse_list = []
        mae_list = []
        r2_list = []
        for col in meta['test_cols']:
            pred_col = f"{col}{pred_suffix}"
            if pred_col not in df_pred.columns:
                raise KeyError(f"é¢„æµ‹åˆ— {pred_col} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ predict_and_attach çš„ overwrite/pred_suffix å‚æ•°")
            y_true = df_true[col].to_numpy()
            y_pred = df_pred[pred_col].to_numpy()
            rmse = mean_squared_error(y_true, y_pred, squared=False)
            mae = mean_absolute_error(y_true, y_pred)
            r2 = r2_score(y_true, y_pred)
            per_col[col] = {'rmse': float(rmse), 'mae': float(mae), 'r2': float(r2)}
            rmse_list.append(rmse)
            mae_list.append(mae)
            r2_list.append(r2)
        per_col['aggregate'] = {
            'rmse_mean': float(np.mean(rmse_list)),
            'mae_mean': float(np.mean(mae_list)),
            'r2_mean': float(np.mean(r2_list))
        }
        results.append(per_col)
    return results


# ================================================================
# 6ï¸âƒ£ ç»˜å›¾å‡½æ•°
# ================================================================
def plot_predictions_for_dfs(
    predicted_dfs: List[pd.DataFrame],
    meta: Dict[str, Any],
    save_dir: str = "plots",
    pred_suffix: str = "_pred"
) -> None:
    """
    ä¸ºæ¯ä¸ª DataFrame ç”Ÿæˆé¢„æµ‹ vs å®é™… çš„ç”µæµæ›²çº¿å›¾å¹¶ä¿å­˜ã€‚
    - æ¯ä¸ª df ç”Ÿæˆä¸€ä¸ªå­æ–‡ä»¶å¤¹ã€‚
    - æ¯ä¸ªè¢«é¢„æµ‹åˆ—å•ç‹¬æˆå›¾ã€‚
    """
    os.makedirs(save_dir, exist_ok=True)

    for i, df_pred in enumerate(predicted_dfs):
        voltage = df_pred[meta["voltage_col"]].to_numpy()
        df_dir = os.path.join(save_dir, f"df_{i+1}")
        os.makedirs(df_dir, exist_ok=True)

        for col in meta["test_cols"]:
            pred_col = f"{col}{pred_suffix}"
            if pred_col not in df_pred.columns:
                continue
            y_true = df_pred[col].to_numpy()
            y_pred = df_pred[pred_col].to_numpy()

            plt.figure(figsize=(8, 5))
            plt.plot(voltage, y_true, label="True", lw=2)
            plt.plot(voltage, y_pred, "--", label="Predicted", lw=2)
            plt.xlabel("Voltage")
            plt.ylabel("Current")
            plt.title(f"DF {i+1} â€” {col}: True vs Predicted")
            plt.legend()
            plt.grid(True)
            plt.tight_layout()

            save_path = os.path.join(df_dir, f"{col}_comparison.png")
            plt.savefig(save_path, dpi=300)
            plt.close()


# ================================================================
# 7ï¸âƒ£ ä¿å­˜è¯„ä¼°ç»“æœå‡½æ•°
# ================================================================
def save_experiment_results(
    metrics_list: List[Dict[str, Any]],
    predicted_dfs: List[pd.DataFrame],
    save_root: str = "experiment_results",
    save_preds: bool = True
) -> str:
    """
    ä¿å­˜é¢„æµ‹è¯„ä¼°æŒ‡æ ‡å’Œé¢„æµ‹åçš„ DataFrameã€‚
    è¿”å›ä¿å­˜ç›®å½•è·¯å¾„ã€‚
    """
    # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = os.path.join(save_root, f"predicted_results")
    os.makedirs(save_dir, exist_ok=True)

    # ä¿å­˜ metrics æ±‡æ€»
    all_metrics = []
    for i, m in enumerate(metrics_list):
        agg = m["aggregate"]
        all_metrics.append({
            "DF_index": i + 1,
            "RMSE_mean": agg["rmse_mean"],
            "MAE_mean": agg["mae_mean"],
            "R2_mean": agg["r2_mean"],
        })
    metrics_df = pd.DataFrame(all_metrics)
    metrics_df.to_csv(os.path.join(save_dir, "summary_metrics.csv"), index=False)

    # ä¿å­˜æ¯ä¸ª df çš„è¯¦ç»†åˆ—æŒ‡æ ‡
    for i, m in enumerate(metrics_list):
        df_metrics = pd.DataFrame(m).T
        df_metrics.to_csv(os.path.join(save_dir, f"df_{i+1}_metrics.csv"))

    # å¯é€‰ä¿å­˜é¢„æµ‹åçš„ DataFrame
    if save_preds:
        pred_dir = os.path.join(save_dir, "predicted_dfs")
        os.makedirs(pred_dir, exist_ok=True)
        for i, df in enumerate(predicted_dfs):
            df.to_csv(os.path.join(pred_dir, f"df_{i+1}_pred.csv"), index=False)

    return save_dir


# ================================================================
# 8ï¸âƒ£ å…¨æµç¨‹ä¸»æ§å‡½æ•°
# ================================================================
def full_experiment_pipeline(
    dfs: List[pd.DataFrame],
    train_ratio: float = 0.9,
    include_voltage: bool = True,
    include_baseline: bool = True,
    cv_folds: int = 5,
    random_state: int = 42,
    n_estimators: int = 200,
    save_root: str = "experiment_results",
    retrain: bool = True
):
    """
    å…¨æµç¨‹å°è£…ï¼š
      1. æ„å»ºç‰¹å¾ä¸æ ‡ç­¾
      2. è®­ç»ƒ + äº¤å‰éªŒè¯è¯„ä¼°
      3. é¢„æµ‹å¹¶é™„åŠ 
      4. ç‹¬ç«‹è¯„ä¼°
      5. ç»˜å›¾ä¸ä¿å­˜ç»“æœ
    """
    os.makedirs(save_root, exist_ok=True)

    log.info("ğŸ§© æ„å»ºç‰¹å¾ä¸æ ‡ç­¾...")
    X, y, meta = build_feature_target_from_dfs(
        dfs,
        train_ratio=train_ratio,
        include_voltage=include_voltage,
        include_baseline=include_baseline
    )

    model_path = os.path.join(save_root, "trained_model.joblib")
    metrics_path = os.path.join(save_root, "cv_metrics.pkl")
    y_pred_path = os.path.join(save_root, "y_pred_cv.npy")

    if (not retrain) and all(os.path.exists(p) for p in [model_path, metrics_path, y_pred_path]):
        # âœ… ä»æ–‡ä»¶ä¸­ç›´æ¥åŠ è½½
        log.info("ğŸŸ¢ æ£€æµ‹åˆ°å·²æœ‰æ¨¡å‹ç¼“å­˜ï¼Œè·³è¿‡é‡æ–°è®­ç»ƒã€‚")
        model = joblib.load(model_path)
        with open(metrics_path, "rb") as f:
            metrics_cv = pickle.load(f)
        y_pred_cv = np.load(y_pred_path)
        log.info("âœ… æˆåŠŸåŠ è½½ç¼“å­˜æ¨¡å‹ä¸ç»“æœã€‚")

    else:
        # ğŸš€ é‡æ–°è®­ç»ƒæ¨¡å‹
        log.info("âš™ï¸ è®­ç»ƒæ¨¡å‹ + äº¤å‰éªŒè¯...")
        model, metrics_cv, y_pred_cv = train_and_evaluate_multioutput(
            X, y, cv_folds=cv_folds, random_state=random_state, n_estimators=n_estimators
        )
        log.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œäº¤å‰éªŒè¯å¹³å‡ RMSE = %.6f", metrics_cv["aggregate"]["rmse_mean"])

        # ğŸ’¾ ä¿å­˜æ¨¡å‹ä¸ç»“æœ
        joblib.dump(model, model_path)
        with open(metrics_path, "wb") as f:
            pickle.dump(metrics_cv, f)
        np.save(y_pred_path, y_pred_cv)
        log.info("ğŸ’¾ æ¨¡å‹ä¸ç»“æœå·²ä¿å­˜åˆ° %s", save_root)

    # ================================================================
    # ğŸ¯ æ®‹å·®è¯Šæ–­å›¾
    # ================================================================

    y_pred_flat = y_pred_cv.ravel()
    y_true_flat = y.ravel()
    residuals = y_true_flat - y_pred_flat

    # ç¤ºä¾‹æ•°æ®
    residual = y[:, 0] - y_pred_cv[:, 0]  # ç¬¬ä¸€ä¸ªè¾“å‡ºçš„æ®‹å·®
    x1, x2, x3 = X[:, 0], X[:, 1], X[:, 2]

    fig = go.Figure(data=[
        go.Scatter3d(
            x=x1, y=x2, z=residual,
            mode='markers',
            marker=dict(
                size=5,
                color=residual,  # é¢œè‰²æ˜ å°„æ®‹å·®å€¼
                colorscale='RdBu',
                colorbar=dict(title='Residual'),
                opacity=0.7
            ),
            text=[f"y_true={yt:.3f}<br>y_pred={yp:.3f}" for yt, yp in zip(y[:, 0], y_pred_cv[:, 0])],
            hovertemplate="x1=%{x:.2f}<br>x2=%{y:.2f}<br>res=%{z:.3f}<br>%{text}"
        )
    ])

    fig.update_layout(
        title="3D Residual Cloud (Output 1)",
        scene=dict(
            xaxis_title="Feature 1",
            yaxis_title="Feature 2",
            zaxis_title="Residual"
        ),
        template="plotly_dark",
        height=700
    )

    fig.show()

    # fig.write_html(f"{save_root}/residual_cloud_output1.html", auto_open=True)

    plt.figure(figsize=(6, 5))
    plt.scatter(y_pred_flat, residuals, alpha=0.3)
    plt.axhline(0, color='r', linestyle='--')
    plt.xlabel("Predicted")
    plt.ylabel("Residual")
    plt.title("Residuals vs Predicted")
    plt.grid(True)
    plt.tight_layout()

    res_plot_path = os.path.join(save_root, "residuals_vs_predicted.png")
    plt.savefig(res_plot_path, dpi=300)
    plt.close()

    # ä¿å­˜æ®‹å·®æ•°æ®ï¼ˆå¯ä¾›å¤–éƒ¨ç»˜å›¾ï¼‰
    pd.DataFrame({
        "y_true": y_true_flat,
        "y_pred": y_pred_flat,
        "residual": residuals
    }).to_csv(os.path.join(save_root, "residuals_data.csv"), index=False)

    # ---- (2) æ®‹å·®åˆ†å¸ƒç›´æ–¹å›¾ ----
    plt.figure(figsize=(6, 4))
    plt.hist(residuals, bins=40, color='skyblue', edgecolor='k', alpha=0.7, density=True)
    plt.title("Residual Distribution")
    plt.xlabel("Residual")
    plt.ylabel("Density")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(save_root, "residual_hist.png"), dpi=300)
    plt.close()

    # ---- (3) æ®‹å·® QQå›¾ ----
    import scipy.stats as stats
    plt.figure(figsize=(5, 5))
    stats.probplot(residuals, dist="norm", plot=plt)
    plt.title("QQ-Plot of Residuals")
    plt.tight_layout()
    plt.savefig(os.path.join(save_root, "residual_qqplot.png"), dpi=300)
    plt.close()


    # # ================================================================
    # # ğŸŒ² ç‰¹å¾é‡è¦æ€§ (Permutation Importance)
    # # ================================================================
    #
    # X_imputed = Pipeline([
    #     ('imputer', SimpleImputer(strategy='mean')),
    #     ('scaler', StandardScaler())
    # ]).fit_transform(X)
    #
    # result_perm = permutation_importance(
    #     model, X_imputed, y, n_repeats=10, random_state=random_state, n_jobs=-1
    # )
    #
    # importances_mean = result_perm.importances_mean
    # importances_std = result_perm.importances_std
    #
    # # ç»˜å›¾
    # feature_names = [f"F{i}" for i in range(X.shape[1])]
    # plt.figure(figsize=(8, 5))
    # sorted_idx = np.argsort(importances_mean)[::-1]
    # plt.bar(range(len(importances_mean)), importances_mean[sorted_idx], yerr=importances_std[sorted_idx], capsize=3)
    # plt.xticks(range(len(importances_mean)), np.array(feature_names)[sorted_idx], rotation=45)
    # plt.ylabel("Importance")
    # plt.title("Permutation Feature Importance (mean Â± std)")
    # plt.tight_layout()
    # plt.savefig(os.path.join(save_root, "feature_importance.png"), dpi=300)
    # plt.close()
    #
    # # ä¿å­˜æ•°æ®
    # pd.DataFrame({
    #     "feature": feature_names,
    #     "importance_mean": importances_mean,
    #     "importance_std": importances_std
    # }).to_csv(os.path.join(save_root, "feature_importance.csv"), index=False)
    #
    # # ================================================================
    # # ğŸ“Š å…³é”®å˜é‡è§£é‡Š (PDP + SHAP)
    # # ================================================================
    #
    # # ä»…é€‰å‰3ä¸ªé‡è¦ç‰¹å¾ç»˜åˆ¶ PDP
    # top3_features = [feature_names[i] for i in sorted_idx[:3]]
    #
    # fig, ax = plt.subplots(figsize=(8, 6))
    # PartialDependenceDisplay.from_estimator(model, X_imputed, features=sorted_idx[:3], feature_names=feature_names, ax=ax, target=0)
    # plt.tight_layout()
    # plt.savefig(os.path.join(save_root, "pdp_top3.png"), dpi=300)
    # plt.close()
    #
    # # --- SHAPåˆ†æ ---
    # explainer = shap.Explainer(model.named_steps['reg'])
    # shap_values = explainer(X_imputed[:500])  # å–éƒ¨åˆ†æ ·æœ¬é˜²æ­¢è¿‡æ…¢
    #
    # shap.summary_plot(shap_values, X_imputed[:500], feature_names=feature_names, show=False)
    # plt.tight_layout()
    # plt.savefig(os.path.join(save_root, "shap_summary.png"), dpi=300)
    # plt.close()
    #
    # # ä¿å­˜ shap å€¼æ•°æ®ï¼ˆå¯å¤–éƒ¨ç»˜åˆ¶ï¼‰
    # for out_idx in range(shap_values.values.shape[2]):
    #     shap_df = pd.DataFrame(shap_values.values[:, :, out_idx], columns=feature_names)
    #     shap_df.to_csv(os.path.join(save_root, f"shap_values_output{out_idx}.csv"), index=False)

    log.info("ğŸ”® é¢„æµ‹æ‰€æœ‰ DataFrame ...")
    predicted_dfs = predict_and_attach(model, dfs, meta)

    log.info("ğŸ“ è¯„ä¼°é¢„æµ‹æ€§èƒ½ ...")
    metrics_list = evaluate_predictions_on_dfs(predicted_dfs, dfs, meta)

    # ================================================================
    # ğŸ”¥ è¾“å‡ºé—´ç›¸å…³æ€§çƒ­åŠ›å›¾
    # ================================================================
    y_true_df = pd.DataFrame(y, columns=[f"Ytrue_{j}" for j in range(y.shape[1])])
    y_pred_df = pd.DataFrame(y_pred_cv, columns=[f"Ypred_{j}" for j in range(y.shape[1])])
    corr_df = pd.concat([y_true_df, y_pred_df], axis=1).corr()

    plt.figure(figsize=(10, 8))
    plt.imshow(corr_df, cmap="coolwarm", interpolation="nearest")
    plt.title("Correlation between True & Predicted Outputs")
    plt.colorbar(label="Correlation coefficient")
    plt.xticks(range(len(corr_df.columns)), corr_df.columns, rotation=90)
    plt.yticks(range(len(corr_df.index)), corr_df.index)
    plt.tight_layout()
    plt.savefig(os.path.join(save_root, "output_correlation_heatmap.png"), dpi=300)
    plt.close()

    corr_df.to_csv(os.path.join(save_root, "output_correlation.csv"))


    rmse_total = 0
    mae_total = 0
    r2_total = 0
    for res in metrics_list:
        rmse_total += res["aggregate"]["rmse_mean"]
        mae_total += res["aggregate"]["mae_mean"]
        r2_total += res["aggregate"]["r2_mean"]

    total_test = len(metrics_list)
    mean_metrics = f"rmse_mean: {rmse_total/total_test}\n" \
                   f"mae_mean: {mae_total / total_test}\n" \
                   f"r2_mean: {r2_total / total_test}\n"

    log.debug(mean_metrics)
    # ä¿å­˜å…¨éƒ¨å¹³å‡æŒ‡æ ‡
    with open(f"{save_root}/mean_metrics.txt", "w", encoding="utf-8") as f:
        f.write(mean_metrics)

    log.info("ğŸ¨ ç»˜åˆ¶å¹¶ä¿å­˜é¢„æµ‹æ›²çº¿ ...")
    plot_predictions_for_dfs(predicted_dfs, meta, save_dir=os.path.join(save_root, "plots"))

    log.info("ğŸ’¾ ä¿å­˜å®éªŒç»“æœ ...")
    save_dir = save_experiment_results(metrics_list, predicted_dfs, save_root=save_root)

    log.debug(f"âœ… å…¨éƒ¨å®éªŒå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š{save_dir}")
    return model, metrics_list, save_dir


if __name__ == "__main__":
    # å¼€å§‹è®¡æ—¶
    log.start_timer()

    base_dir = "data"  # å­æ–‡ä»¶å¤¹æ‰€åœ¨ç›®å½•

    # ç»™å®šå·²ç»è¿è¡Œè¿‡çš„æ–‡ä»¶å¤¹æ•°é‡ï¼Œéœ€è¦å…¨éƒ¨è¿è¡Œåˆ™è®¾ç½®ä¸º0ï¼Œå¦åˆ™å°†è·³è¿‡å‰ skip_count ä¸ªæ–‡ä»¶å¤¹çš„è¿è¡Œ
    # skip_count = 0
    skip_count = 0
    # æ˜¯å¦é‡æ–°è®­ç»ƒæ¨¡å‹
    retrain = False

    all_folders = os.listdir(base_dir)

    # å¾ªç¯å¤„ç†æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶å¤¹
    cnt = 0
    for folder_name in all_folders:
        cnt += 1
        if cnt <= skip_count or folder_name == "None":
            log.warning(f"folder {folder_name} skipped!")
            continue
        current_folder = os.path.join(base_dir, folder_name)
        dfs = load_dataset(current_folder)

        # dfs æ˜¯ 10 ä¸ª 625x19 çš„ DataFrame åˆ—è¡¨
        model, metrics_list, save_dir = full_experiment_pipeline(
            dfs,
            train_ratio=0.8,
            include_voltage=False,
            include_baseline=True,
            cv_folds=5,
            n_estimators=300,
            save_root=f"predicted_results/{folder_name}",
            retrain=retrain
        )

    # ç»“æŸè®¡æ—¶
    log.elapsed()
